{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvXdh4tfT12A",
        "outputId": "84039994-94ce-4a97-dd29-4487c77e6f1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28.0\n",
        "!pip install huggingface_hub\n",
        "!pip install groq\n",
        "!pip install requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "on0LT5JUUerz",
        "outputId": "362d5ee8-de37-4a7e-a90b-54505e55d722"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai==0.28.0 in /usr/local/lib/python3.11/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai==0.28.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai==0.28.0) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai==0.28.0) (3.11.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28.0) (2025.1.31)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.0) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.0) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.0) (1.19.0)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.1.31)\n",
            "Requirement already satisfied: groq in /usr/local/lib/python3.11/dist-packages (0.22.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.11.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "from groq import Groq\n",
        "from huggingface_hub import InferenceClient\n",
        "import pandas as pd\n",
        "import json\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "frULk7TKUoV1"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/My Drive/data.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "case_row = data.iloc[497]\n",
        "full_text = case_row['text']\n",
        "case_summary = full_text\n",
        "accusation = full_text\n",
        "testimony_prompt = full_text"
      ],
      "metadata": {
        "id": "QVVZN8PAU0tX"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0w0-XWWpKhyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import google.colab\n",
        "from huggingface_hub import InferenceClient, login, HfFolder\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "\n",
        "hf_token = os.getenv(\"HF_TOKEN\")\n",
        "\n",
        "\n",
        "if hf_token and not HfFolder.get_token():\n",
        "    login(token=hf_token)\n",
        "\n",
        "\n",
        "hf_tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-2.7B\", token=hf_token) #tokenizer\n",
        "\n",
        "#truncate the prompt\n",
        "def truncate_prompt(prompt, max_input_tokens=3900):\n",
        "    input_ids = hf_tokenizer(prompt, return_tensors=\"pt\").input_ids[0]\n",
        "    if len(input_ids) > max_input_tokens:\n",
        "        prompt = hf_tokenizer.decode(input_ids[:max_input_tokens], skip_special_tokens=True)\n",
        "    return prompt\n"
      ],
      "metadata": {
        "id": "wj8MW4HNOED3"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import json\n",
        "import regex\n",
        "import requests\n",
        "\n",
        "class Agent:\n",
        "    class GroqHandler:\n",
        "        def __init__(self):\n",
        "            self.api_key = \"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\"\n",
        "            self.base_url = \"https://api.groq.com/openai/v1/chat/completions\"\n",
        "        def query(self, prompt, role_context):\n",
        "            headers = {\n",
        "                'Authorization': f'Bearer {self.api_key}',\n",
        "                'Content-Type': 'application/json'\n",
        "            }\n",
        "            payload = {\n",
        "                \"model\": \"llama3-70b-8192\",\n",
        "                \"messages\": [\n",
        "                    {\"role\": \"system\", \"content\": role_context},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                \"max_tokens\": 300,\n",
        "                \"temperature\": 0.3\n",
        "            }\n",
        "            rate_limited_once = False\n",
        "            for attempt in range(3):\n",
        "                try:\n",
        "                    response = requests.post(\n",
        "                        self.base_url,\n",
        "                        headers=headers,\n",
        "                        json=payload,\n",
        "                        timeout=30\n",
        "                    )\n",
        "                    if response.status_code == 429:\n",
        "                        wait_time = float(response.headers.get(\"Retry-After\", 60))\n",
        "                        if not rate_limited_once:\n",
        "                            print(f\"Rate limited. Waiting {wait_time}s (suppressed further messages)...\")\n",
        "                            rate_limited_once = True\n",
        "                        time.sleep(wait_time)\n",
        "                        continue\n",
        "                    response.raise_for_status()\n",
        "                    return response.json()['choices'][0]['message']['content'].strip()\n",
        "                except Exception as e:\n",
        "                    print(f\"API Error: {str(e)}\")\n",
        "                    time.sleep(2 ** attempt)\n",
        "            return \"API request failed after retries\"\n",
        "    def __init__(self, name, role, llm_type):\n",
        "        self.name = name\n",
        "        self.role = role\n",
        "        self.llm_type = llm_type.lower()\n",
        "        self.memory = []\n",
        "        if self.llm_type == \"groq\":\n",
        "            self.client = Agent.GroqHandler()\n",
        "        else:\n",
        "            from huggingface_hub import InferenceClient\n",
        "            self.client = InferenceClient(\"google/flan-t5-base\")\n",
        "    def generate_response(self, prompt):\n",
        "        context = \"\\n\".join([f\"User: {m['prompt']}\\n{self.name}: {m['response']}\"\n",
        "                           for m in self.memory[-2:]])\n",
        "        full_prompt = f\"{context}\\nUser: {prompt}\\n{self.name}:\"\n",
        "        try:\n",
        "            if self.llm_type == \"hf\":\n",
        "                response = self.client.text_generation(full_prompt, max_new_tokens=300)\n",
        "            else:\n",
        "                response = self.client.query(full_prompt, f\"You are {self.name}, a {self.role}\")\n",
        "            self.memory.append({\"prompt\": prompt, \"response\": response})\n",
        "            return response\n",
        "        except Exception as e:\n",
        "            print(f\"Response error: {str(e)}\")\n",
        "            return \"Error generating response\"\n",
        "\n",
        "class JudgeDrivenTrial:\n",
        "    def __init__(self, case_summary):\n",
        "        self.case_summary = case_summary[:500]\n",
        "        self.agents = {}\n",
        "        self.phase_sequence = [\n",
        "            \"opening\",\n",
        "            \"direct-examination\",\n",
        "            \"cross-examination\",\n",
        "            \"closing\",\n",
        "            \"jury-deliberation\"\n",
        "        ]\n",
        "        self.current_phase_index = 0\n",
        "        self.examination_record = []\n",
        "        self._init_core_agents()\n",
        "    def _init_core_agents(self):\n",
        "        self.add_agent(\"Justice Ray\", \"judge\", \"groq\")\n",
        "        self.add_agent(\"Ava\", \"prosecutor\", \"groq\")\n",
        "        self.add_agent(\"Leo\", \"defense\", \"groq\")\n",
        "        self.add_agent(\"Emily\", \"plaintiff\", \"groq\")\n",
        "        self.add_agent(\"Jury Foreman\", \"jury\", \"groq\")\n",
        "        self.judge = self.agents[\"judge\"]\n",
        "    def add_agent(self, name, role, llm_type):\n",
        "        if role.lower() in self.agents:\n",
        "            raise ValueError(f\"Role {role} already exists\")\n",
        "        self.agents[role.lower()] = Agent(name, role, llm_type)\n",
        "    def _safe_json_parse(self, raw_response):\n",
        "        try:\n",
        "            clean = regex.sub(r'``````', '', raw_response, flags=regex.DOTALL)\n",
        "            match = regex.search(r'\\{(?:[^{}]|(?R))*\\}', clean, regex.DOTALL)\n",
        "            return json.loads(match.group()) if match else {}\n",
        "        except Exception as e:\n",
        "            print(f\"JSON Parse Error: {str(e)}\")\n",
        "            return {}\n",
        "    def judicial_order(self, prompt):\n",
        "        response = self.judge.generate_response(f\"{prompt} Respond with valid JSON only.\")\n",
        "        return self._safe_json_parse(response)\n",
        "    def conduct_trial(self):\n",
        "        self._open_court()\n",
        "        while self.current_phase_index < len(self.phase_sequence):\n",
        "            current_phase = self.phase_sequence[self.current_phase_index]\n",
        "            print(f\"\\n=== {current_phase.replace('-', ' ').title()} Phase ===\")\n",
        "            if current_phase == \"opening\":\n",
        "                self._handle_openings()\n",
        "            elif current_phase == \"direct-examination\":\n",
        "                self._handle_direct_examination()\n",
        "            elif current_phase == \"cross-examination\":\n",
        "                self._handle_cross_examination()\n",
        "            elif current_phase == \"closing\":\n",
        "                self._handle_closing()\n",
        "            elif current_phase == \"jury-deliberation\":\n",
        "                self._handle_jury_deliberation()\n",
        "            self.current_phase_index += 1\n",
        "        self._deliver_verdict()\n",
        "    def _open_court(self):\n",
        "        print(f\"\\nJudge {self.judge.name}: Court is now in session.\")\n",
        "        print(f\"Case: {self.case_summary}...\")\n",
        "    def _handle_openings(self):\n",
        "        order = self.judicial_order('''{\"order\": [\"plaintiff\", \"prosecutor\", \"defense\"]}''') \\\n",
        "                .get(\"order\", [\"plaintiff\", \"prosecutor\", \"defense\"])\n",
        "        for role in order:\n",
        "            agent = self.agents.get(role.lower())\n",
        "            if agent:\n",
        "                statement = agent.generate_response(f\"Opening statement: {self.case_summary}\")\n",
        "                print(f\"\\n{agent.role.title()}: {statement[:300]}...\")\n",
        "                time.sleep(1)\n",
        "    def _handle_direct_examination(self):\n",
        "        if witness := self.agents.get(\"witness\"):\n",
        "            print(f\"\\nDirect examination of witness: {witness.name}\")\n",
        "            self.examination_record = []\n",
        "            for q_num in range(2):\n",
        "                question = self.agents[\"prosecutor\"].generate_response(\n",
        "                    f\"Direct question {q_num+1} for {witness.name} about {self.case_summary[:200]}\"\n",
        "                )\n",
        "                response = witness.generate_response(question)\n",
        "                self.examination_record.append((question, response))\n",
        "                print(f\"\\nQ{q_num+1}: {question[:150]}\\nA: {response[:200]}...\")\n",
        "                time.sleep(1)\n",
        "    def _handle_cross_examination(self):\n",
        "        if witness := self.agents.get(\"witness\"):\n",
        "            print(f\"\\nCross-examination of witness: {witness.name}\")\n",
        "            for i, (question, response) in enumerate(self.examination_record):\n",
        "                cross_q = self.agents[\"defense\"].generate_response(\n",
        "                    f\"Cross-examine this testimony: Q: {question} A: {response}\"\n",
        "                )\n",
        "                cross_a = witness.generate_response(cross_q)\n",
        "                print(f\"\\nDefense Cross-Q{i+1}: {cross_q[:150]}\\nA: {cross_a[:200]}...\")\n",
        "                # Optionally, let prosecutor rebut\n",
        "                rebuttal = self.agents[\"prosecutor\"].generate_response(\n",
        "                    f\"Rebut the defense's cross-examination: {cross_q} | Witness answer: {cross_a}\"\n",
        "                )\n",
        "                print(f\"\\nProsecutor Rebuttal: {rebuttal[:200]}...\")\n",
        "                time.sleep(1)\n",
        "    def _handle_closing(self):\n",
        "        print(\"\\nClosing Arguments:\")\n",
        "        for role in [\"plaintiff\", \"prosecutor\", \"defense\"]:\n",
        "            agent = self.agents.get(role)\n",
        "            if agent:\n",
        "                closing = agent.generate_response(\"Summarize key points\")\n",
        "                print(f\"\\n{agent.role.title()}: {closing[:300]}...\")\n",
        "                time.sleep(1)\n",
        "    def _handle_jury_deliberation(self):\n",
        "        print(\"\\nJury Deliberation:\")\n",
        "        if jury := self.agents.get(\"jury\"):\n",
        "            deliberation = jury.generate_response(\n",
        "                \"Discuss the evidence and arguments presented in the case and recommend a verdict\"\n",
        "            )\n",
        "            print(f\"\\nJury Foreman: {deliberation[:300]}...\")\n",
        "            time.sleep(1)\n",
        "    def _deliver_verdict(self):\n",
        "        jury_recommendation = self.agents[\"jury\"].generate_response(\n",
        "            \"Based on all evidence and arguments, recommend a verdict (guilty/not guilty/remanded)\"\n",
        "        )\n",
        "        verdict_data = self.judicial_order(f'''{{\n",
        "            \"verdict\": \"{jury_recommendation}\",\n",
        "            \"reasoning\": {{\n",
        "                \"jurisdiction\": \"<analysis>\",\n",
        "                \"procedure\": \"<evaluation>\",\n",
        "                \"legal_basis\": \"<citations>\"\n",
        "            }}\n",
        "        }}''')\n",
        "        print(\"\\n=== FINAL JUDGMENT ===\")\n",
        "        print(f\"Jury Recommendation: {jury_recommendation[:200]}\")\n",
        "        print(f\"Court Verdict: {verdict_data.get('verdict', 'Case dismissed')}\")\n",
        "        print(\"Legal Reasoning:\")\n",
        "        for k, v in verdict_data.get(\"reasoning\", {}).items():\n",
        "            print(f\"- {k.title()}: {v[:200] or 'Not addressed'}...\")\n",
        "        print(\"\\nCourt is adjourned.\")\n",
        "\n",
        "# ---- Usage ----\n",
        "if __name__ == \"__main__\":\n",
        "    trial = JudgeDrivenTrial(case_summary)\n",
        "    trial.add_agent(\"Bob\", \"witness\", \"groq\")\n",
        "    trial.conduct_trial()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYTcrv5KjfD9",
        "outputId": "1d1a7661-ee11-4cc3-f4ff-465dfaa328bc"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Judge Justice Ray: Court is now in session.\n",
            "Case: CIVIL APPELLATE JURISDICTION Civil Appeal No. 220 of 1964. Appeal from the judgment and order dated April 17, 1961 of the Calcutta High Court in Appeal from Original Order No. 11 5 of 1960. Chowdhury, S. Mukherjee and S. N. Mukherjee, for the appellant. Sen, V. A. Seyid Muhammad, P. K. Das and P. K. Bose for the respondents. The Judgment of the Court was delivered by Gajendragadkar, C.J. This appeal arises out of a suit filed by the appellant, Mirza Ali Akbar Kashani, against the two respondents...\n",
            "\n",
            "=== Opening Phase ===\n",
            "\n",
            "Plaintiff: Your Honor, esteemed members of the court, I, Emily, am the plaintiff in this case, and I am represented by my counsel, Sen, V. A. Seyid Muhammad, P. K. Das, and P. K. Bose. I am here today to seek justice and redress for the grievances that I have suffered at the hands of the appellant, Mirza Ali A...\n",
            "\n",
            "Prosecutor: Honorable Chief Justice Gajendragadkar and esteemed members of the court, I, Ava, prosecutor for the respondents, stand before you today to present our case against the appellant, Mirza Ali Akbar Kashani. The appeal before us arises from a suit filed by the appellant in the Calcutta High Court, whic...\n",
            "\n",
            "Defense: for a declaration that the appellant is the sole and absolute owner of certain premises known as 14/1, Beadon Street, Calcutta, and for a permanent injunction restraining the respondents from interfering with the appellant's possession and enjoyment of the said premises....\n",
            "\n",
            "=== Direct Examination Phase ===\n",
            "\n",
            "Direct examination of witness: Bob\n",
            "\n",
            "Q1: Can you please clarify what you would like to ask about the case, Mr. Chowdhury? Are you seeking information about the appeal process, the judgment of\n",
            "A: No, no, I'm not Mr. Chowdhury. I'm Bob, a witness in the case. I'm not a lawyer or anything. I just happened to be at the scene when the incident occurred. I'm here to answer any questions you have ab...\n",
            "\n",
            "Q2: Mr. Chowdhury, can you explain the nature of the original suit filed by the appellant, Mirza Ali Akbar Kashani, in the Calcutta High Court, and what w\n",
            "A: Wait, I think there's been a mistake. Like I said, I'm Bob, a witness. I don't know anything about the legal stuff. I wasn't involved in the lawsuit or anything. I just saw something happen that day, ...\n",
            "\n",
            "=== Cross Examination Phase ===\n",
            "\n",
            "Cross-examination of witness: Bob\n",
            "\n",
            "Defense Cross-Q1: I apologize for the mistake, Bob. Thank you for clarifying. As the defense, I'd like to ask you some questions about what you witnessed on the day of \n",
            "A: Yeah, I'd be happy to tell you what I saw. So, I was walking down Beadon Street, just minding my own business, when I saw a commotion outside number 14/1. There were a few people arguing, and it looke...\n",
            "\n",
            "Prosecutor Rebuttal: I'd like to clarify some points from your testimony, Mr. Chowdhury. You stated that you didn't know if the person trying to get into the building was Mirza Ali Akbar Kashani or not, as you'd never see...\n",
            "\n",
            "Defense Cross-Q2: No worries, Bob. Let's start fresh. As the defense, I'm interested in understanding what you witnessed on the day of the incident. You mentioned you s\n",
            "A: Like I said, I was just walking down the street when I saw a bunch of people arguing outside number 14/1. It looked like a pretty intense dispute, but I didn't know what it was about. There were a few...\n",
            "\n",
            "Prosecutor Rebuttal: Mr. Chowdhury, I'd like to clarify some points from your testimony. You mentioned that you saw a dispute between a few people trying to get into the building and others trying to stop them. However, y...\n",
            "\n",
            "=== Closing Phase ===\n",
            "\n",
            "Closing Arguments:\n",
            "\n",
            "Plaintiff: Here are the key points from my opening statement:\n",
            "\n",
            "* I, Emily, am the plaintiff in this case.\n",
            "* I am represented by my counsel, Sen, V. A. Seyid Muhammad, P. K. Das, and P. K. Bose.\n",
            "* The appellant, Mirza Ali Akbar Kashani, filed a suit against me and the other respondent.\n",
            "* I am seeking justice an...\n",
            "Rate limited. Waiting 9.0s (suppressed further messages)...\n",
            "\n",
            "Prosecutor: Here are the key points from the witness's testimony and my rebuttal as a prosecutor:\n",
            "\n",
            "**Witness's Testimony:**\n",
            "\n",
            "* The witness, Mr. Chowdhury, saw a commotion outside 14/1 Beadon Street, Calcutta, on the day of the incident.\n",
            "* He saw a few people arguing, including one person trying to get into the ...\n",
            "Rate limited. Waiting 4.0s (suppressed further messages)...\n",
            "\n",
            "Defense: Based on the testimony, here are the key points:\n",
            "\n",
            "* The witness, Bob, is not a lawyer and was not involved in the lawsuit. He is a witness who happened to be at the scene of the incident.\n",
            "* Bob is not familiar with the legal aspects of the case, including the original suit filed by the appellant, Mi...\n",
            "\n",
            "=== Jury Deliberation Phase ===\n",
            "\n",
            "Jury Deliberation:\n",
            "\n",
            "Jury Foreman: Ladies and gentlemen of the jury, after careful deliberation and thorough review of the evidence presented, I believe it is our duty to deliver a fair and just verdict. Let us recap the key points of the case.\n",
            "\n",
            "The prosecution presented a compelling argument, highlighting the defendant's suspicious ...\n",
            "Rate limited. Waiting 6.0s (suppressed further messages)...\n",
            "Rate limited. Waiting 3.0s (suppressed further messages)...\n",
            "\n",
            "=== FINAL JUDGMENT ===\n",
            "Jury Recommendation: After further deliberation and careful consideration of all the evidence and arguments presented, I recommend a verdict of \"not guilty\". While the prosecution has presented a strong case, I believe th\n",
            "Court Verdict: Case dismissed\n",
            "Legal Reasoning:\n",
            "\n",
            "Court is adjourned.\n"
          ]
        }
      ]
    }
  ]
}